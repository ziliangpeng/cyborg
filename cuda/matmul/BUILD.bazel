load("@rules_cuda//cuda:defs.bzl", "cuda_library", "cuda_binary", "cuda_test")

# ============================================================================
# Matrix Multiplication Implementation Libraries
# ============================================================================

# Matrix initialization utilities
cuda_library(
    name = "matrix_init",
    srcs = ["matrix_init.cu"],
    hdrs = ["matrix_init.h"],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Base interface
cc_library(
    name = "matmul_kernel_h",
    hdrs = ["matmul_kernel.h"],
)

# Naive matrix multiplication implementation
cuda_library(
    name = "matmul_naive",
    srcs = ["matmul_naive.cu"],
    hdrs = [
        "matmul_naive.h",
        "matmul_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# cuBLAS baseline kernel
cuda_library(
    name = "matmul_cublas",
    srcs = ["matmul_cublas.cu"],
    hdrs = [
        "matmul_cublas.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    linkopts = [
        "-L/usr/local/cuda/lib64",
        "-lcublas",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# WMMA Tensor Core kernel (FP16)
cuda_library(
    name = "matmul_wmma",
    srcs = ["matmul_wmma.cu"],
    hdrs = [
        "matmul_wmma.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Global memory coalescing optimization (Kernel 2)
cuda_library(
    name = "matmul_coalesced",
    srcs = ["matmul_coalesced.cu"],
    hdrs = [
        "matmul_coalesced.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Shared memory caching optimization (Kernel 3)
cuda_library(
    name = "matmul_smem",
    srcs = ["matmul_smem.cu"],
    hdrs = [
        "matmul_smem.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# 1D block tiling optimization (Kernel 4)
cuda_library(
    name = "matmul_1d_blocktile",
    srcs = ["matmul_1d_blocktile.cu"],
    hdrs = [
        "matmul_1d_blocktile.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# 2D block tiling optimization (Kernel 5)
cuda_library(
    name = "matmul_2d_blocktile",
    srcs = ["matmul_2d_blocktile.cu"],
    hdrs = [
        "matmul_2d_blocktile.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Vectorized memory access optimization (Kernel 6)
cuda_library(
    name = "matmul_vectorized",
    srcs = ["matmul_vectorized.cu"],
    hdrs = [
        "matmul_vectorized.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Warp tiling optimization (Kernel 10)
cuda_library(
    name = "matmul_warptile",
    srcs = ["matmul_warptile.cu"],
    hdrs = [
        "matmul_warptile.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# BF16 WMMA Tensor Core kernel (Ampere+)
# BF16 WMMA requires SM80+
cuda_library(
    name = "matmul_wmma_bf16",
    srcs = ["matmul_wmma_bf16.cu"],
    hdrs = [
        "matmul_wmma_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# cuBLAS BF16 baseline (Ampere+)
cuda_library(
    name = "matmul_cublas_bf16",
    srcs = ["matmul_cublas_bf16.cu"],
    hdrs = [
        "matmul_cublas_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    linkopts = [
        "-L/usr/local/cuda/lib64",
        "-lcublas",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA Tensor Core kernel with double buffering
cuda_library(
    name = "matmul_wmma_optimized",
    srcs = ["matmul_wmma_optimized.cu"],
    hdrs = [
        "matmul_wmma_optimized.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# WMMA Tensor Core kernel V2 - aggressive optimizations
cuda_library(
    name = "matmul_wmma_v2",
    srcs = ["matmul_wmma_v2.cu"],
    hdrs = [
        "matmul_wmma_v2.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# WMMA Tensor Core kernel V3 - balanced optimization
cuda_library(
    name = "matmul_wmma_v3",
    srcs = ["matmul_wmma_v3.cu"],
    hdrs = [
        "matmul_wmma_v3.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel
cuda_library(
    name = "matmul_wmma_opt_bf16",
    srcs = ["matmul_wmma_opt_bf16.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V2 - larger tiles
cuda_library(
    name = "matmul_wmma_opt_bf16_v2",
    srcs = ["matmul_wmma_opt_bf16_v2.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v2.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V3 - smaller BK for occupancy
cuda_library(
    name = "matmul_wmma_opt_bf16_v3",
    srcs = ["matmul_wmma_opt_bf16_v3.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v3.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V4 - multi-stage pipelining
cuda_library(
    name = "matmul_wmma_opt_bf16_v4",
    srcs = ["matmul_wmma_opt_bf16_v4.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v4.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V5 - high arithmetic intensity
cuda_library(
    name = "matmul_wmma_opt_bf16_v5",
    srcs = ["matmul_wmma_opt_bf16_v5.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v5.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V6 - small tiles, high occupancy
cuda_library(
    name = "matmul_wmma_opt_bf16_v6",
    srcs = ["matmul_wmma_opt_bf16_v6.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v6.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V7 - large warp tiles
cuda_library(
    name = "matmul_wmma_opt_bf16_v7",
    srcs = ["matmul_wmma_opt_bf16_v7.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v7.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V8 - vectorized loads
cuda_library(
    name = "matmul_wmma_opt_bf16_v8",
    srcs = ["matmul_wmma_opt_bf16_v8.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v8.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Optimized WMMA BF16 kernel V10 - instruction scheduling
cuda_library(
    name = "matmul_wmma_opt_bf16_v10",
    srcs = ["matmul_wmma_opt_bf16_v10.cu"],
    hdrs = [
        "matmul_wmma_opt_bf16_v10.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# MMA PTX BF16 kernel - direct PTX instructions
cuda_library(
    name = "matmul_mma_bf16",
    srcs = ["matmul_mma_bf16.cu"],
    hdrs = [
        "matmul_mma_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Async BF16 kernel - cp.async with 3-stage pipeline
cuda_library(
    name = "matmul_async_bf16",
    srcs = ["matmul_async_bf16.cu"],
    hdrs = [
        "matmul_async_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Swizzle BF16 kernel - swizzled shared memory
cuda_library(
    name = "matmul_swizzle_bf16",
    srcs = ["matmul_swizzle_bf16.cu"],
    hdrs = [
        "matmul_swizzle_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Large tile BF16 kernel - 256x128 tiles with register reuse
cuda_library(
    name = "matmul_large_tile_bf16",
    srcs = ["matmul_large_tile_bf16.cu"],
    hdrs = [
        "matmul_large_tile_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# 3-stage pipelined BF16 kernel
cuda_library(
    name = "matmul_stage3_bf16",
    srcs = ["matmul_stage3_bf16.cu"],
    hdrs = [
        "matmul_stage3_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Tuned BF16 kernel - 128x256 tiles with RLRL pattern
cuda_library(
    name = "matmul_tuned_bf16",
    srcs = ["matmul_tuned_bf16.cu"],
    hdrs = [
        "matmul_tuned_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Compact BF16 kernel - 64x64 tiles for high occupancy
cuda_library(
    name = "matmul_compact_bf16",
    srcs = ["matmul_compact_bf16.cu"],
    hdrs = [
        "matmul_compact_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Unrolled BF16 kernel - 4x K unrolling
cuda_library(
    name = "matmul_unroll_bf16",
    srcs = ["matmul_unroll_bf16.cu"],
    hdrs = [
        "matmul_unroll_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Hybrid BF16 kernel - 3-stage pipeline + 2x K unroll
cuda_library(
    name = "matmul_hybrid_bf16",
    srcs = ["matmul_hybrid_bf16.cu"],
    hdrs = [
        "matmul_hybrid_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Best BF16 kernel - 64x64 warp tiles + 4x K unroll
cuda_library(
    name = "matmul_best_bf16",
    srcs = ["matmul_best_bf16.cu"],
    hdrs = [
        "matmul_best_bf16.h",
        "matmul_kernel.h",
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# ============================================================================
# Matrix Multiplication Main Binary
# ============================================================================

cuda_binary(
    name = "matmul",
    srcs = ["matmul.cpp"],
    deps = [
        ":matmul_naive",
        ":matmul_coalesced",
        ":matmul_smem",
        ":matmul_1d_blocktile",
        ":matmul_2d_blocktile",
        ":matmul_vectorized",
        ":matmul_warptile",
        ":matmul_cublas",
        ":matmul_wmma",
        ":matmul_wmma_bf16",
        ":matmul_cublas_bf16",
        ":matmul_wmma_optimized",
        ":matmul_wmma_v2",
        ":matmul_wmma_v3",
        ":matmul_wmma_opt_bf16",
        ":matmul_wmma_opt_bf16_v2",
        ":matmul_wmma_opt_bf16_v3",
        ":matmul_wmma_opt_bf16_v4",
        ":matmul_wmma_opt_bf16_v5",
        ":matmul_wmma_opt_bf16_v6",
        ":matmul_wmma_opt_bf16_v7",
        ":matmul_wmma_opt_bf16_v8",
        ":matmul_wmma_opt_bf16_v10",
        ":matmul_mma_bf16",
        ":matmul_async_bf16",
        ":matmul_swizzle_bf16",
        ":matmul_large_tile_bf16",
        ":matmul_stage3_bf16",
        ":matmul_tuned_bf16",
        ":matmul_compact_bf16",
        ":matmul_unroll_bf16",
        ":matmul_hybrid_bf16",
        ":matmul_best_bf16",
        ":matmul_kernel_h",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    linkopts = [
        "-L/usr/local/cuda/lib64",
        "-lcublas",
    ],
    target_compatible_with = ["//constraints:cuda"],
)

# ============================================================================
# Test Targets
# ============================================================================

# Test naive implementation on small matrices
cuda_test(
    name = "matmul_naive_64_test",
    srcs = ["matmul.cpp"],
    args = ["--size", "64", "--method", "naive", "--verify"],
    deps = [
        ":matmul_naive",
        ":matmul_kernel_h",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
)

cuda_test(
    name = "matmul_naive_128_test",
    srcs = ["matmul.cpp"],
    args = ["--size", "128", "--method", "naive", "--verify"],
    deps = [
        ":matmul_naive",
        ":matmul_kernel_h",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
)

cuda_test(
    name = "matmul_naive_256_test",
    srcs = ["matmul.cpp"],
    args = ["--size", "256", "--method", "naive", "--verify"],
    deps = [
        ":matmul_naive",
        ":matmul_kernel_h",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
)

cuda_test(
    name = "matmul_naive_512_test",
    srcs = ["matmul.cpp"],
    args = ["--size", "512", "--method", "naive", "--verify"],
    deps = [
        ":matmul_naive",
        ":matmul_kernel_h",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
)

# cuBLAS tests for various sizes
cuda_test(
    name = "matmul_cublas_256_test",
    srcs = ["matmul.cpp"],
    deps = [
        ":matmul_kernel_h",
        ":matmul_naive",
        ":matmul_cublas",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    args = ["--size", "256", "--method", "cublas", "--verify"],
    target_compatible_with = ["//constraints:cuda"],
)

cuda_test(
    name = "matmul_cublas_1024_test",
    srcs = ["matmul.cpp"],
    deps = [
        ":matmul_kernel_h",
        ":matmul_naive",
        ":matmul_cublas",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    args = ["--size", "1024", "--method", "cublas", "--verify"],
    target_compatible_with = ["//constraints:cuda"],
)

cuda_test(
    name = "matmul_cublas_2048_test",
    srcs = ["matmul.cpp"],
    deps = [
        ":matmul_kernel_h",
        ":matmul_naive",
        ":matmul_cublas",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    args = ["--size", "2048", "--method", "cublas", "--verify"],
    target_compatible_with = ["//constraints:cuda"],
)

# WMMA tests for various sizes
cuda_test(
    name = "matmul_wmma_256_test",
    srcs = ["matmul.cpp"],
    deps = [
        ":matmul_kernel_h",
        ":matmul_naive",
        ":matmul_cublas",
        ":matmul_wmma",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    args = ["--size", "256", "--method", "wmma", "--verify"],
    target_compatible_with = ["//constraints:cuda"],
)

cuda_test(
    name = "matmul_wmma_1024_test",
    srcs = ["matmul.cpp"],
    deps = [
        ":matmul_kernel_h",
        ":matmul_naive",
        ":matmul_cublas",
        ":matmul_wmma",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    args = ["--size", "1024", "--method", "wmma", "--verify"],
    target_compatible_with = ["//constraints:cuda"],
)

cuda_test(
    name = "matmul_wmma_2048_test",
    srcs = ["matmul.cpp"],
    deps = [
        ":matmul_kernel_h",
        ":matmul_naive",
        ":matmul_cublas",
        ":matmul_wmma",
        ":matrix_init",
        "//cuda:cuda_utils",
    ],
    args = ["--size", "2048", "--method", "wmma", "--verify"],
    target_compatible_with = ["//constraints:cuda"],
)

# ============================================================================
# Test Suite (run all matmul tests)
# ============================================================================

test_suite(
    name = "all_tests",
    tests = [
        ":matmul_naive_64_test",
        ":matmul_naive_128_test",
        ":matmul_naive_256_test",
        ":matmul_naive_512_test",
        ":matmul_cublas_256_test",
        ":matmul_cublas_1024_test",
        ":matmul_cublas_2048_test",
        ":matmul_wmma_256_test",
        ":matmul_wmma_1024_test",
        ":matmul_wmma_2048_test",
    ],
)
