load("@rules_cuda//cuda:defs.bzl", "cuda_library", "cuda_binary", "cuda_test")

# ============================================================================
# Softmax Implementation Libraries (one per approach)
# ============================================================================

# Naive implementation (numerically unstable)
cuda_library(
    name = "softmax_naive",
    srcs = ["softmax_naive.cu"],
    hdrs = [
        "softmax_naive.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
        "//cuda/reduce:sum_reduce",
        "//cuda/reduce:max_reduce",
        "//cuda/elementwise:normalize",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Multi-pass implementation (stable baseline)
cuda_library(
    name = "softmax_multipass",
    srcs = ["softmax_multipass.cu"],
    hdrs = ["softmax_multipass.h"],
    deps = [
        "//cuda:cuda_utils",
        "//cuda/reduce:sum_reduce",
        "//cuda/reduce:max_reduce",
        "//cuda/elementwise:normalize",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Fused 3-kernel implementation (optimized)
cuda_library(
    name = "softmax_fused3",
    srcs = ["softmax_fused3.cu"],
    hdrs = [
        "softmax_fused3.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
        "//cuda/reduce:sum_reduce",
        "//cuda/reduce:max_reduce",
        "//cuda/elementwise:normalize",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Fused 2-kernel implementation using cooperative groups with grid-stride loops
cuda_library(
    name = "softmax_fused2",
    srcs = ["softmax_fused2.cu"],
    hdrs = [
        "softmax_fused2.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        ":softmax_fused3",  # Reuse softmaxFused3_BlockStats from 3-kernel version
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Fused 1-kernel implementation (skeleton)
cuda_library(
    name = "softmax_fused1",
    srcs = ["softmax_fused1.cu"],
    hdrs = ["softmax_fused1.h"],
    deps = [
        "//cuda:cuda_utils",
        "//cuda/reduce:sum_reduce",
        "//cuda/reduce:max_reduce",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Online softmax implementation (skeleton - deprecated)
cuda_library(
    name = "softmax_online",
    srcs = ["softmax_online.cu"],
    hdrs = ["softmax_online.h"],
    deps = [
        "//cuda:cuda_utils",
        "//cuda/reduce:sum_reduce",
        "//cuda/reduce:max_reduce",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Online softmax - simple thread-level implementation (educational)
cuda_library(
    name = "softmax_online_simple",
    srcs = ["softmax_online_simple.cu"],
    hdrs = [
        "softmax_online_simple.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
        "//cuda/elementwise:normalize",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Online softmax - warp-level cooperative implementation (performance)
cuda_library(
    name = "softmax_online_warp",
    srcs = ["softmax_online_warp.cu"],
    hdrs = [
        "softmax_online_warp.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# CUB block-level softmax implementation (using NVIDIA CUB BlockReduce)
cuda_library(
    name = "softmax_cub_block",
    srcs = ["softmax_cub_block.cu"],
    hdrs = [
        "softmax_cub_block.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
        "//cuda/elementwise:normalize",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# CUB device-level softmax implementation (using NVIDIA CUB DeviceReduce)
cuda_library(
    name = "softmax_cub_device",
    srcs = ["softmax_cub_device.cu"],
    hdrs = [
        "softmax_cub_device.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# cuDNN-based softmax implementation (industry-standard deep learning library)
cuda_library(
    name = "softmax_cudnn",
    srcs = ["softmax_cudnn.cu"],
    hdrs = [
        "softmax_cudnn.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    linkopts = [
        "-L/lib/x86_64-linux-gnu",
        "-lcudnn",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Tiny softmax implementation (single-warp, minimal overhead, optimal for â‰¤1K)
cuda_library(
    name = "softmax_tiny",
    srcs = ["softmax_tiny.cu"],
    hdrs = [
        "softmax_tiny.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# Small softmax implementation (single-block, hybrid reduction, optimal for 1K-8K)
cuda_library(
    name = "softmax_small",
    srcs = ["softmax_small.cu"],
    hdrs = [
        "softmax_small.h",
        "softmax_kernel.h",  # Base interface
    ],
    deps = [
        "//cuda:cuda_utils",
    ],
    target_compatible_with = ["//constraints:cuda"],
    includes = [".."],
)

# ============================================================================
# Softmax Main Binary (Performance Benchmark)
# ============================================================================

cuda_binary(
    name = "softmax",
    srcs = ["softmax.cpp"],
    deps = [
        ":softmax_naive",
        ":softmax_multipass",
        ":softmax_fused3",
        ":softmax_fused2",
        ":softmax_fused1",
        ":softmax_online",
        ":softmax_online_simple",
        ":softmax_online_warp",
        ":softmax_cub_block",
        ":softmax_cub_device",
        ":softmax_cudnn",
        ":softmax_tiny",
        ":softmax_small",
        "//cuda:cuda_utils",
        "//cuda:vector_init",
        "//cuda/common:benchmark_utils",
    ],
    linkopts = [
        "-L/lib/x86_64-linux-gnu",
        "-lcudnn",
    ],
    target_compatible_with = ["//constraints:cuda"],
    visibility = ["//cuda:__pkg__"],
)

# ============================================================================
# Correctness Tests (googletest-based, manual - not run in CI)
# ============================================================================

cuda_test(
    name = "softmax_test",
    srcs = ["softmax_test.cpp"],
    deps = [
        ":softmax_naive",
        ":softmax_fused3",
        ":softmax_fused2",
        ":softmax_online_simple",
        ":softmax_online_warp",
        ":softmax_cub_block",
        ":softmax_cub_device",
        ":softmax_cudnn",
        ":softmax_tiny",
        ":softmax_small",
        "//cuda:cuda_utils",
        "@googletest//:gtest_main",
    ],
    linkopts = [
        "-L/lib/x86_64-linux-gnu",
        "-lcudnn",
    ],
    target_compatible_with = ["//constraints:cuda"],
    tags = ["manual"],  # Not run in CI - requires GPU
)
